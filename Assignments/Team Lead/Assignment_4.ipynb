{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Model building libraries"
      ],
      "metadata": {
        "id": "z3dAzSLMGUrs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_695c7VF1KW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import load_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing NLTK libraries"
      ],
      "metadata": {
        "id": "x86th3rLGfRL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import nltk\n",
        "nltk.download('stopwords')  \n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "pe-xHqbvGHQ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading dataset and preprocessing"
      ],
      "metadata": {
        "id": "lNWeL5mQGln8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "O0QgMfJZGSDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd/content/drive/MyDrive/Colab Notebooks"
      ],
      "metadata": {
        "id": "EHo9aOiJGo7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/AI_IBM/spam.csv',delimiter=',',encoding='latin-1')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "xIdaBgA5Gsju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['Unnamed: 2','Unnamed: 3', 'Unnamed: 4'],axis=1,inplace=True) \n",
        "df.info()"
      ],
      "metadata": {
        "id": "6voLWmhMN-y1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(['v1']).size()"
      ],
      "metadata": {
        "id": "hY4uSqBDOE-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Label Encoding Required Column\n",
        "X = df.v2\n",
        "Y = df.v1\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)\n",
        "Y = Y.reshape(-1,1)"
      ],
      "metadata": {
        "id": "PqeDzAwfOIZy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test and train data split \n",
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.15)"
      ],
      "metadata": {
        "id": "t5A-PWk8OLJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenisation function\n",
        "max_words = 1000\n",
        "max_len = 150\n",
        "tok = Tokenizer(num_words=max_words)\n",
        "tok.fit_on_texts(X_train)\n",
        "sequences = tok.texts_to_sequences(X_train)\n",
        "sequences_matrix = sequence.pad_sequences(sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "APBV59hwOPdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Model"
      ],
      "metadata": {
        "id": "KMltpxADORRB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add layers (LSTM ,Dense-(HiddenLayers),Ouput)"
      ],
      "metadata": {
        "id": "hZApgG1oOWeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LSTM model\n",
        "inputs = Input(name='InputLayer',shape=[max_len])\n",
        "layer = Embedding(max_words,50,input_length=max_len)(inputs)\n",
        "layer = LSTM(64)(layer)\n",
        "layer = Dense(256,name='FullyConnectedLayer1')(layer)\n",
        "layer = Activation('relu')(layer)\n",
        "layer = Dropout(0.5)(layer)\n",
        "layer = Dense(1,name='OutputLayer')(layer)\n",
        "layer = Activation('sigmoid')(layer)"
      ],
      "metadata": {
        "id": "G9nm_ielOcqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=inputs,outputs=layer)\n",
        "model.summary()\n",
        "model.compile(loss='binary_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XnCx4YHdOrDQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(sequences_matrix,Y_train,batch_size=128,epochs=25,validation_split=0.2)"
      ],
      "metadata": {
        "id": "E6-BfeNFPjmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"Ai_Spam_Identifier\")"
      ],
      "metadata": {
        "id": "BoowMZ_qPmXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sequences = tok.texts_to_sequences(X_test)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,maxlen=max_len)"
      ],
      "metadata": {
        "id": "o_XjYsXpPo4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = model.evaluate(test_sequences_matrix,Y_test)\n",
        "print('Accuracy: {:0.3f}'.format(accuracy[1]))"
      ],
      "metadata": {
        "id": "GsIdCyXDPujY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_sequences_matrix)\n",
        "print(y_pred[25:40].round(3))"
      ],
      "metadata": {
        "id": "B68i6umfPxIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_test[25:40])"
      ],
      "metadata": {
        "id": "RDjdgW9MP0Es"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}